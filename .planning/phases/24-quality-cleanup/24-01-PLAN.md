---
phase: 24-quality-cleanup
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/jamma/lmm/runner_streaming.py
  - src/jamma/kinship/compute.py
  - tests/test_snp_filter_perf.py
autonomous: true

must_haves:
  truths:
    - "Chunk-level SNP filtering uses np.searchsorted for O(log n) lookup instead of linear scan"
    - "Streaming LMM runner produces identical results before and after the optimization"
    - "Kinship streaming computation produces identical results before and after the optimization"
  artifacts:
    - path: "src/jamma/lmm/runner_streaming.py"
      provides: "searchsorted-based chunk filtering replacing Python for-loop"
      contains: "searchsorted"
    - path: "src/jamma/kinship/compute.py"
      provides: "searchsorted-based chunk filtering replacing vectorized comparison"
      contains: "searchsorted"
    - path: "tests/test_snp_filter_perf.py"
      provides: "Regression test validating searchsorted produces same indices as naive scan"
  key_links:
    - from: "src/jamma/lmm/runner_streaming.py"
      to: "np.searchsorted"
      via: "Binary search on sorted snp_indices array"
      pattern: "np\\.searchsorted"
    - from: "src/jamma/kinship/compute.py"
      to: "np.searchsorted"
      via: "Binary search on sorted snp_indices array"
      pattern: "np\\.searchsorted"
---

<objective>
Replace linear-scan SNP filtering in chunk processing with binary search (np.searchsorted) for O(log n) per-chunk lookup.

Purpose: The streaming LMM runner (runner_streaming.py line 353) uses a Python for-loop iterating over ALL filtered SNP indices for every file chunk. The kinship compute (compute.py line 376) uses vectorized comparison but still scans all indices. With 91k+ filtered SNPs and many chunks, this is O(chunks * filtered_snps). Using searchsorted on the already-sorted snp_indices array gives O(chunks * log(filtered_snps)).

Output: Optimized chunk filtering in both streaming runners, regression test proving equivalence.
</objective>

<execution_context>
@/Users/mdenyer/.claude/get-shit-done/workflows/execute-plan.md
@/Users/mdenyer/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@src/jamma/lmm/runner_streaming.py
@src/jamma/kinship/compute.py
@src/jamma/core/snp_filter.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Replace linear SNP filtering with searchsorted in both streaming modules</name>
  <files>
    src/jamma/lmm/runner_streaming.py
    src/jamma/kinship/compute.py
  </files>
  <action>
In both files, `snp_indices` is produced by `np.where(snp_mask)[0]` and is therefore already sorted (monotonically increasing). This is the key invariant that makes searchsorted valid.

**runner_streaming.py (lines 350-357)** — Replace the Python for-loop:
```python
chunk_filtered_indices = []
chunk_filtered_local_idx = []
chunk_filtered_col_idx = []
for i, snp_idx in enumerate(snp_indices):
    if file_start <= snp_idx < file_end:
        chunk_filtered_indices.append(snp_idx)
        chunk_filtered_local_idx.append(i)
        chunk_filtered_col_idx.append(snp_idx - file_start)
```

With searchsorted:
```python
left = np.searchsorted(snp_indices, file_start, side="left")
right = np.searchsorted(snp_indices, file_end, side="left")
chunk_snp_slice = snp_indices[left:right]

if len(chunk_snp_slice) == 0:
    continue

chunk_filtered_local_idx = np.arange(left, right)
chunk_filtered_col_idx_arr = chunk_snp_slice - file_start
```

Then update the downstream code:
- `geno_subset = chunk[:, chunk_filtered_col_idx_arr].copy()` (already correct with array)
- `filtered_means_broadcast = filtered_means[chunk_filtered_local_idx].reshape(1, -1)` (works with array)
- Remove the `chunk_filtered_indices` list (no longer needed, was unused downstream beyond the length check)

**kinship/compute.py (line 376)** — Replace vectorized comparison:
```python
chunk_snp_mask = (snp_indices >= file_start) & (snp_indices < file_end)
chunk_filtered_indices = snp_indices[chunk_snp_mask] - file_start
```

With searchsorted:
```python
left = np.searchsorted(snp_indices, file_start, side="left")
right = np.searchsorted(snp_indices, file_end, side="left")
chunk_filtered_indices = snp_indices[left:right] - file_start
```

Both replacements preserve identical semantics: find indices in [file_start, file_end) range. The sorted invariant of snp_indices guarantees correctness.
  </action>
  <verify>
Run existing tests to verify no regression:
```bash
uv run pytest tests/test_streaming.py tests/test_kinship_compute.py tests/test_kinship_validation.py -x
```
All tests must pass with identical results.
  </verify>
  <done>Both runner_streaming.py and kinship/compute.py use np.searchsorted instead of linear scan. Existing tests pass unchanged.</done>
</task>

<task type="auto">
  <name>Task 2: Add regression test for searchsorted chunk filtering equivalence</name>
  <files>tests/test_snp_filter_perf.py</files>
  <action>
Create a focused test that validates the searchsorted approach produces identical indices to naive scan. This is a tier0 (unit) test — no I/O, no GEMMA reference.

Test cases:
1. **Basic overlap**: snp_indices = [2, 5, 8, 12, 15], chunk [4, 10) → should find [5, 8]
2. **No overlap**: snp_indices = [2, 5, 8], chunk [10, 20) → empty
3. **Full overlap**: snp_indices = [0, 1, 2, 3, 4], chunk [0, 5) → all
4. **Edge boundaries**: snp_indices = [5, 10], chunk [5, 11) → both; chunk [5, 10) → only [5]
5. **Large sorted array**: 10,000 random sorted indices, random chunk ranges, verify searchsorted matches naive loop

The test should:
- Define a helper `naive_chunk_filter(snp_indices, file_start, file_end)` that does the loop
- Define a helper `searchsorted_chunk_filter(snp_indices, file_start, file_end)` that uses searchsorted
- Assert both produce identical local_indices and col_indices for all test cases
- Mark as `@pytest.mark.tier0`

Also add a parameterized test with multiple chunk boundaries across a large snp_indices array to verify boundary correctness (off-by-one is the risk with searchsorted side parameter).
  </action>
  <verify>
```bash
uv run pytest tests/test_snp_filter_perf.py -x -v
```
All tests pass.
  </verify>
  <done>Regression test validates searchsorted produces identical results to naive scan across edge cases and large arrays.</done>
</task>

</tasks>

<verification>
1. `uv run pytest tests/test_snp_filter_perf.py -x -v` — new regression tests pass
2. `uv run pytest tests/test_streaming.py tests/test_kinship_compute.py tests/test_kinship_validation.py -x` — existing tests pass unchanged
3. `grep -n "searchsorted" src/jamma/lmm/runner_streaming.py src/jamma/kinship/compute.py` — both files use searchsorted
4. No Python for-loops remain for chunk filtering in either file
</verification>

<success_criteria>
- Both streaming modules use np.searchsorted for O(log n) chunk filtering
- All existing streaming and kinship tests pass without modification
- New regression test covers edge cases (empty, full, boundary)
</success_criteria>

<output>
After completion, create `.planning/phases/24-quality-cleanup/24-01-SUMMARY.md`
</output>
